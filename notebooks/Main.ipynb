{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e6f2f3d-726c-4a34-a682-0369ae338048",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# End-to-end backend run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f841d830-ca60-4cf5-a4f6-e6321e813f7b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2c03fe52-2eae-4365-b869-93cb158fd332",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "This notebook contains an end-to-end run of the code that runs in the backend of our Streamlit app. We developed this backend using Databricks, and later fleshed it out as a fully fledged app with a user interface developed locally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f4d2c383-1e94-4b0a-ad51-d765bf659f50",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Step 1. Necessary installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5f03d57-1dec-49f3-9cfd-e9bee4f146b6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "ee8cb3cb-4bdb-48e1-a4f1-2f8267d6bd56",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001b[0m\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.1.17-py3-none-any.whl (867 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 867.6/867.6 kB 19.7 MB/s eta 0:00:00\n",
      "Collecting openai\n",
      "  Downloading openai-1.25.2-py3-none-any.whl (312 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 312.9/312.9 kB 69.6 MB/s eta 0:00:00\n",
      "Collecting streamlit\n",
      "  Downloading streamlit-1.34.0-py2.py3-none-any.whl (8.5 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 113.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas in /databricks/python3/lib/python3.10/site-packages (1.4.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from langchain) (2.28.1)\n",
      "Collecting SQLAlchemy<3,>=1.4\n",
      "  Downloading SQLAlchemy-2.0.30-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 136.4 MB/s eta 0:00:00\n",
      "Collecting PyYAML>=5.3\n",
      "  Downloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 705.5/705.5 kB 112.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pydantic<3,>=1 in /databricks/python3/lib/python3.10/site-packages (from langchain) (1.10.6)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1\n",
      "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7\n",
      "  Downloading dataclasses_json-0.6.5-py3-none-any.whl (28 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /databricks/python3/lib/python3.10/site-packages (from langchain) (1.21.5)\n",
      "Collecting langchain-core<0.2.0,>=0.1.48\n",
      "  Downloading langchain_core-0.1.50-py3-none-any.whl (302 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 302.8/302.8 kB 73.1 MB/s eta 0:00:00\n",
      "Collecting langchain-community<0.1,>=0.0.36\n",
      "  Downloading langchain_community-0.0.36-py3-none-any.whl (2.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 130.8 MB/s eta 0:00:00\n",
      "Collecting langsmith<0.2.0,>=0.1.17\n",
      "  Downloading langsmith-0.1.54-py3-none-any.whl (116 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 116.7/116.7 kB 38.4 MB/s eta 0:00:00\n",
      "Collecting aiohttp<4.0.0,>=3.8.3\n",
      "  Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 122.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /databricks/python3/lib/python3.10/site-packages (from langchain) (8.1.0)\n",
      "Collecting anyio<5,>=3.5.0\n",
      "  Downloading anyio-4.3.0-py3-none-any.whl (85 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 85.6/85.6 kB 26.7 MB/s eta 0:00:00\n",
      "Collecting tqdm>4\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.3/78.3 kB 30.8 MB/s eta 0:00:00\n",
      "Collecting httpx<1,>=0.23.0\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 75.6/75.6 kB 26.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Collecting sniffio\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Collecting typing-extensions<5,>=4.7\n",
      "  Downloading typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /databricks/python3/lib/python3.10/site-packages (from streamlit) (6.1)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7\n",
      "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 207.3/207.3 kB 57.0 MB/s eta 0:00:00\n",
      "Collecting watchdog>=2.1.5\n",
      "  Downloading watchdog-4.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 83.0/83.0 kB 27.4 MB/s eta 0:00:00\n",
      "Collecting cachetools<6,>=4.0\n",
      "  Downloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: click<9,>=7.0 in /databricks/python3/lib/python3.10/site-packages (from streamlit) (8.0.4)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
      "Collecting altair<6,>=4.0\n",
      "  Downloading altair-5.3.0-py3-none-any.whl (857 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 857.8/857.8 kB 124.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyarrow>=7.0 in /databricks/python3/lib/python3.10/site-packages (from streamlit) (8.0.0)\n",
      "Requirement already satisfied: packaging<25,>=16.8 in /databricks/python3/lib/python3.10/site-packages (from streamlit) (21.3)\n",
      "Collecting pydeck<1,>=0.8.0b4\n",
      "  Downloading pydeck-0.9.0-py2.py3-none-any.whl (6.9 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.9/6.9 MB 117.0 MB/s eta 0:00:00\n",
      "Collecting rich<14,>=10.14.0\n",
      "  Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 240.7/240.7 kB 69.3 MB/s eta 0:00:00\n",
      "Collecting toml<2,>=0.10.1\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting protobuf<5,>=3.20\n",
      "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 294.6/294.6 kB 67.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in /databricks/python3/lib/python3.10/site-packages (from streamlit) (9.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /databricks/python3/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.10/site-packages (from pandas) (2022.1)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 239.5/239.5 kB 69.2 MB/s eta 0:00:00\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 301.6/301.6 kB 69.4 MB/s eta 0:00:00\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 124.3/124.3 kB 43.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: attrs>=17.3.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (21.4.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /databricks/python3/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (4.16.0)\n",
      "Requirement already satisfied: jinja2 in /databricks/python3/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (2.11.3)\n",
      "Collecting toolz\n",
      "  Downloading toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.1/56.1 kB 20.4 MB/s eta 0:00:00\n",
      "Collecting exceptiongroup>=1.0.2\n",
      "  Downloading exceptiongroup-1.2.1-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /databricks/python3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0\n",
      "  Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 49.3/49.3 kB 18.2 MB/s eta 0:00:00\n",
      "Collecting typing-inspect<1,>=0.4.0\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.7/62.7 kB 22.2 MB/s eta 0:00:00\n",
      "Collecting httpcore==1.*\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 77.9/77.9 kB 26.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: certifi in /databricks/python3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2022.9.14)\n",
      "Collecting h11<0.15,>=0.13\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.3/58.3 kB 21.7 MB/s eta 0:00:00\n",
      "Collecting jsonpointer>=1.9\n",
      "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Collecting packaging<25,>=16.8\n",
      "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.0/53.0 kB 15.9 MB/s eta 0:00:00\n",
      "Collecting orjson<4.0.0,>=3.9.14\n",
      "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 142.5/142.5 kB 48.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Collecting pygments<3.0.0,>=2.13.0\n",
      "  Downloading pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 101.5 MB/s eta 0:00:00\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 87.5/87.5 kB 27.6 MB/s eta 0:00:00\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (616 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 616.0/616.0 kB 84.1 MB/s eta 0:00:00\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /databricks/python3/lib/python3.10/site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.0.1)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /databricks/python3/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.0)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /databricks/python3/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (0.4.3)\n",
      "Installing collected packages: watchdog, typing-extensions, tqdm, toolz, toml, sniffio, smmap, PyYAML, pygments, protobuf, packaging, orjson, multidict, mdurl, jsonpointer, h11, greenlet, frozenlist, exceptiongroup, cachetools, async-timeout, yarl, typing-inspect, SQLAlchemy, pydeck, marshmallow, markdown-it-py, jsonpatch, httpcore, gitdb, anyio, aiosignal, rich, langsmith, httpx, gitpython, dataclasses-json, altair, aiohttp, streamlit, openai, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.3.0\n",
      "    Not uninstalling typing-extensions at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-7cb5fd70-0dc8-4e26-804d-18f931ea0585\n",
      "    Can't uninstall 'typing_extensions'. No files were found to uninstall.\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.11.2\n",
      "    Not uninstalling pygments at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-7cb5fd70-0dc8-4e26-804d-18f931ea0585\n",
      "    Can't uninstall 'Pygments'. No files were found to uninstall.\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.4\n",
      "    Not uninstalling protobuf at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-7cb5fd70-0dc8-4e26-804d-18f931ea0585\n",
      "    Can't uninstall 'protobuf'. No files were found to uninstall.\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 21.3\n",
      "    Not uninstalling packaging at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-7cb5fd70-0dc8-4e26-804d-18f931ea0585\n",
      "    Can't uninstall 'packaging'. No files were found to uninstall.\n",
      "Successfully installed PyYAML-6.0.1 SQLAlchemy-2.0.30 aiohttp-3.9.5 aiosignal-1.3.1 altair-5.3.0 anyio-4.3.0 async-timeout-4.0.3 cachetools-5.3.3 dataclasses-json-0.6.5 exceptiongroup-1.2.1 frozenlist-1.4.1 gitdb-4.0.11 gitpython-3.1.43 greenlet-3.0.3 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.17 langchain-community-0.0.36 langchain-core-0.1.50 langchain-text-splitters-0.0.1 langsmith-0.1.54 markdown-it-py-3.0.0 marshmallow-3.21.2 mdurl-0.1.2 multidict-6.0.5 openai-1.25.2 orjson-3.10.3 packaging-23.2 protobuf-4.25.3 pydeck-0.9.0 pygments-2.18.0 rich-13.7.1 smmap-5.0.1 sniffio-1.3.1 streamlit-1.34.0 toml-0.10.2 toolz-0.12.1 tqdm-4.66.4 typing-extensions-4.11.0 typing-inspect-0.9.0 watchdog-4.0.0 yarl-1.9.4\n",
      "\u001b[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain openai streamlit pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "51a53756-bdd6-4937-b982-be3778c14ceb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Step 2. Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b45ebcc6-f0c5-41a6-bb17-8b071c937bba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/Workspace/Users/pablo.siso@artefact.com/.ide/artefact-hackathon-03-af6736e3/src\")\n",
    "\n",
    "from generate_persona import generate_persona\n",
    "from generate_marketing_mix import generate_marketing_mix\n",
    "from mmx_dict_to_dataframe import mmx_dict_to_dataframe\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a516d83-d9b5-4cae-bfbf-df6a6a223c47",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Step 3. Generate marketing mix strategy from example input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b567796a-64d1-4e01-b655-260f21a09f9c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# OpenAI secret key (necessary to make the code work and not included in repo)\n",
    "openai_api_key = \"your-key\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00cd0609-3a03-4112-9109-8d2ede1c1f16",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Call MMX Generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ff7eeab-4b0c-4f80-828a-530182b0beeb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Open sample input for marketing mix strategy\n",
    "with open(\"sample_ins_and_outs/sample_mmx_input.json\", \"r\") as f:\n",
    "    mmix_strategy_input = json.loads(f.read())\n",
    "\n",
    "# with open(\"sample_ins_and_outs/sample_mmx_output.json\", \"r\") as f:\n",
    "#     strategy = json.loads(f.read())\n",
    "\n",
    "strategy = generate_marketing_mix(product_attributes=mmix_strategy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f4ae8dd-c321-4cde-84cc-0a8effe59317",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'You should definitely invest on': [['YouTube',\n",
       "   \"YouTube is a powerful platform to visually showcase the brewing process, unique flavors, and the story behind Satan's Breath. Creating engaging video content such as behind-the-scenes brewery tours, tasting sessions, and interviews with the brewers can help build brand awareness and connect with the target audience.\"],\n",
       "  ['SEO',\n",
       "   \"Investing in SEO is crucial to ensure that when beer enthusiasts in the Netherlands search for craft IPAs or unique beer flavors, Satan's Breath appears at the top of search engine results. Optimizing website content with relevant keywords, creating high-quality backlinks, and implementing local SEO strategies can drive organic traffic to the website.\"],\n",
       "  ['Email',\n",
       "   \"Email marketing can be highly effective in nurturing relationships with customers and promoting new IPA releases, special events at taprooms, and exclusive offers. Building an email list through website sign-ups and offering personalized recommendations based on customers' flavor preferences can increase engagement and drive repeat purchases.\"]],\n",
       " 'You should consider investing on': [['Tiktok',\n",
       "   \"Tiktok's visual and engaging nature can be leveraged to create short and creative videos showcasing the unique flavors of Satan's Breath, introducing brewing techniques in a fun way, and collaborating with influencers or local beer enthusiasts to reach a wider audience within the target demographic.\"],\n",
       "  ['Billboards',\n",
       "   'Strategic placement of billboards in trendy neighborhoods, near craft beer bars, or on highways leading to the taprooms can increase brand visibility and create intrigue among the target audience. Eye-catching visuals and witty messaging can pique interest and drive foot traffic to the taprooms.'],\n",
       "  ['Paid Search',\n",
       "   'Utilizing paid search ads can complement SEO efforts by targeting specific keywords related to craft IPAs, beer tasting experiences, and local breweries in the Netherlands. Running targeted campaigns with compelling ad copy and landing pages optimized for conversions can increase website traffic and drive sales.']],\n",
       " 'You should stay away from': [['TV',\n",
       "   \"TV advertising may not be the most cost-effective channel to reach the niche market of young, hipster adults in the Netherlands who are more likely to be active on digital platforms. The target audience's media consumption habits lean towards online platforms and social media, making TV ads less targeted and impactful for Satan's Breath.\"],\n",
       "  ['Meta',\n",
       "   \"Considering the product's niche market and the target audience's preferences, investing in Meta platforms like Facebook and Instagram may not yield the desired results. While these platforms offer advertising options, the focus should be on channels that align more closely with the target audience's behavior and interests.\"]],\n",
       " 'Other options': \"Considering the target audience's interest in supporting local brands, collaborating with local influencers or beer bloggers to create sponsored content, hosting beer tasting events at popular local hangout spots, partnering with local breweries for cross-promotions, and participating in craft beer festivals and events can further enhance brand visibility and engagement within the Netherlands market.\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dc809f88-9612-4bd5-8ad5-3c1c1e9fdcc7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Transform JSON to DF Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1064c0a8-1169-43a9-9bfc-b55532079aba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mmx_run_df = mmx_dict_to_dataframe(strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f4176be-b57b-44d7-953a-5131b99840ee",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Write DF to Databricks table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6153e3c2-07dc-48e3-8a1e-276fe4951e42",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.createDataFrame(mmx_run_df).write.mode(\"append\").saveAsTable(\"default.mmx_runs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4dc892a6-aa6d-47ec-a9c0-5bd94ab613ce",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Step 4. Generate marketing persona from example input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e0eddd6-7494-4659-939a-e6601899d466",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with open(\"sample_ins_and_outs/sample_persona_input.json\", \"r\") as f:\n",
    "    persona_input = json.loads(f.read())\n",
    "\n",
    "with open(\"sample_ins_and_outs/sample_persona_output.json\", \"r\") as f:\n",
    "    persona_output = json.loads(f.read())\n",
    "\n",
    "# persona_output = generate_persona(mmix_strategy_input, persona_attributes=persona_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "022dc33d-f93a-44c0-b188-e492abf50b88",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Name': 'Marco, the Italian Beer Connoisseur',\n",
       " 'StrugglesAndPains': 'Marco craves for distinctive ale flavors and quality that are difficult to find in regular supermarket brands or local bars. He has a strong passion for gastronomy, but is often frustrated by the lack of creativity and uniqueness in the beer industry. Traveling extensively, he struggles to find a brand that provides consistent quality and unique flavors wherever he goes.',\n",
       " 'OtherProducts': 'Marco often explores a variety of artisanal food and beverage products, ranging from gourmet cheeses and cured meats to premier wines and unique coffee blends. He also enjoys shopping for high-end travel accessories, showing his taste for quality and style.',\n",
       " 'Goals': 'Marco aspires to discover and enjoy beers that offer non-conventional tastes, tailored towards beer enthusiasts like him. He wants to associate with a brand that values quality and craftsmanship in their brewing techniques. His keen interest also lies in sharing his ale discoveries with friends both online and offline.',\n",
       " 'BenefitsOfProduct': 'Our small-batch India Pale Ales offer Marco the distinct and unique flavors he craves, constantly titillating his discerning palate. The quality of our carefully crafted beers matches his gastronomic interests, while our diverse range provides him a new experience every time. Our availability online and in various local spots supports his wanderlust lifestyle, offering him reliable quality wherever he travels.',\n",
       " 'MarketingTagline': 'Experience the Uncharted Taste of Adventure, Brewed for the Gourmet Wanderer.'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persona_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a626d268-e123-4f74-b23d-22a486074da9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "persona_run_df = pd.DataFrame(persona_output, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05fd2ff8-c6ab-4775-9d26-d0bc382f706e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.createDataFrame(persona_run_df).write.mode(\"append\").saveAsTable(\"default.persona_runs\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Main",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
